{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Tensof Flow Serving docker with our saved model as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cmd = '''docker run --rm\n",
    "         -p 8500:8500                                                         \n",
    "         -v /tmp/tf_tutorial/model:/tmp/model                                             \n",
    "         yesuprelease/tensorflow-serving                                      \n",
    "         bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server   \n",
    "         --model_base_path='/tmp/model'                                       \n",
    "         --model_name='tf_demo'\n",
    "      '''\n",
    "# Run our docker\n",
    "p = subprocess.Popen(cmd.replace('\\n',''), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample data from big query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "s=r'''SELECT regexp_extract(sample_path, '.*(\\\\..+)$') as suffix,\n",
    "             content\n",
    "      FROM  [bigquery-public-data:github_repos.sample_contents]\n",
    "      WHERE RAND() < 1/10\n",
    "          AND content IS NOT NULL\n",
    "          AND content != ''\n",
    "          and length(content) > 1024\n",
    "      HAVING suffix IS NOT NULL             \n",
    "             AND suffix in ('.py','.c','.rb')\n",
    "      LIMIT 100;'''\n",
    "\n",
    "from gcloud import bigquery\n",
    "c = bigquery.Client()\n",
    "query = c.run_sync_query(s)\n",
    "query.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proccess data so we can send it to our model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def transform_content(content):\n",
    "    content = content.encode('utf-8')\n",
    "    content = content[:1024]    \n",
    "    return content\n",
    "\n",
    "code_snippets = np.transpose(np.array([transform_content(row[1]) for row in query.rows if row[0]]))\n",
    "language_codes = np.array([row[0].encode('utf-8') for row in query.rows])\n",
    "\n",
    "print code_snippets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import utils\n",
    "\n",
    "import grpc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start communication channel using grpc, get stub,  build request, and generate protobuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel('localhost:8500')\n",
    "\n",
    "stub = prediction_service_pb2.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = 'tf_demo'\n",
    "request.model_spec.signature_name = 'predict_language'\n",
    "request.inputs['content'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(code_snippets, shape=code_snippets.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = stub.Predict(request, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate results to logits, predicitons and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          13.88054657   0.        ]\n",
      " [  0.           0.          12.50568199]\n",
      " [  0.           0.          26.37464905]\n",
      " [  0.           2.53996301   9.92933846]\n",
      " [  0.           1.68892777  10.62524891]\n",
      " [  0.          11.04464436   1.96848619]\n",
      " [  0.           7.18550587   5.4188714 ]\n",
      " [  0.           0.          12.55268097]\n",
      " [  0.           6.51946783   6.48295641]\n",
      " [  0.           1.95149028  10.25632286]\n",
      " [  0.           0.          29.86507034]\n",
      " [  0.           9.23156166   3.65585852]\n",
      " [  0.           0.96755266  11.06261063]\n",
      " [  0.           0.          14.2930336 ]\n",
      " [  0.           0.          30.63389587]\n",
      " [  0.          17.02863503   0.        ]\n",
      " [  0.          10.00269699   2.74343276]\n",
      " [  0.          35.70146942   0.        ]\n",
      " [  0.          16.2253952    0.        ]\n",
      " [  0.          12.14783573   0.90165758]\n",
      " [  0.           8.61195564   4.03998947]\n",
      " [  0.           9.85961342   2.88267732]\n",
      " [  0.          13.14874458   0.        ]\n",
      " [  0.          10.10594654   2.62282705]\n",
      " [  0.           6.48009348   5.9998498 ]\n",
      " [  0.          13.97139263   0.        ]\n",
      " [  0.          49.71126556   0.        ]\n",
      " [  0.           8.46046734   4.34940577]\n",
      " [  0.           8.10805798   4.28341246]\n",
      " [  0.           0.          19.86172867]\n",
      " [  0.          12.18677044   0.73380804]\n",
      " [  0.          10.49729729   2.256078  ]\n",
      " [  0.           0.          63.67484665]\n",
      " [  0.          12.34583569   0.61395705]\n",
      " [  0.          10.16699696   2.80179811]\n",
      " [  0.          10.67933464   2.1496315 ]\n",
      " [  0.          14.08744717   0.        ]\n",
      " [  0.          15.56142044   0.        ]\n",
      " [  0.          11.3922596    1.47324049]\n",
      " [  0.           0.34126413  11.45635223]\n",
      " [  0.          11.47631741   1.45791352]\n",
      " [  0.           0.44388205  11.61546516]\n",
      " [  0.           3.73458314   9.00148964]\n",
      " [  0.          10.02325439   2.86108875]\n",
      " [  0.          16.09415436   0.        ]\n",
      " [  0.           9.25455284   3.58844399]\n",
      " [  0.          15.57838821   0.        ]\n",
      " [  0.           9.85035992   3.27876592]\n",
      " [  0.          15.96114922   0.        ]\n",
      " [  0.          17.11634636   0.        ]\n",
      " [  0.           9.57877731   3.43037534]\n",
      " [  0.          16.37098312   0.        ]\n",
      " [  0.          12.06081295   0.27874747]\n",
      " [  0.           0.          28.53083038]\n",
      " [  0.          20.78936577   0.        ]\n",
      " [  0.          16.59476852   0.        ]\n",
      " [  0.          12.51669025   0.49507412]\n",
      " [  0.          13.65343094   0.        ]\n",
      " [  0.           4.62237072   7.95507383]\n",
      " [  0.           9.53143215   3.4308126 ]\n",
      " [  0.          14.50804329   0.        ]\n",
      " [  0.           1.63753116  10.7309494 ]\n",
      " [  0.          20.62825584   0.        ]\n",
      " [  0.           3.475842     9.15052605]\n",
      " [  0.           2.7269969    9.59702301]\n",
      " [  0.           8.96322441   3.95964217]\n",
      " [  0.           8.72052765   3.88163757]\n",
      " [  0.          15.21099663   0.        ]\n",
      " [  0.           0.          12.61754608]\n",
      " [  0.          10.71115303   2.29154301]\n",
      " [  0.           0.          33.68291092]\n",
      " [  0.          14.72093105   0.        ]\n",
      " [  0.           6.81371927   5.44026041]\n",
      " [  0.          14.59260273   0.        ]\n",
      " [  0.          17.94476891   0.        ]\n",
      " [  0.           0.          13.00027275]\n",
      " [  0.           3.08307004   9.19244576]\n",
      " [  0.           1.62257361  10.54613304]\n",
      " [  0.           9.67371464   3.16091728]\n",
      " [  0.           2.90813184   9.18778229]\n",
      " [  0.           0.          13.68047142]\n",
      " [  0.          11.13921928   1.88027668]\n",
      " [  0.           3.22153234   9.1928215 ]\n",
      " [  0.           0.          12.96696663]\n",
      " [  0.           7.28957081   5.48717022]\n",
      " [  0.           0.36289388  11.7311821 ]\n",
      " [  0.           0.94677413  11.37167358]\n",
      " [  0.           9.71950436   3.01121283]\n",
      " [  0.          11.44293213   1.46484733]\n",
      " [  0.           0.50655758  11.74304962]\n",
      " [  0.          11.05088997   1.95476115]\n",
      " [  0.           1.08637464  10.50696182]\n",
      " [  0.           1.37940943  10.87832928]\n",
      " [  0.          14.47292137   0.        ]\n",
      " [  0.           4.65928555   7.9534564 ]\n",
      " [  0.           8.25355339   4.68310118]\n",
      " [  0.           1.23760784  10.95723438]\n",
      " [  0.           0.          13.59438133]\n",
      " [  0.           2.45513487   9.90412998]\n",
      " [  0.          15.99835873   0.        ]]\n",
      "accuracy: 0.81\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .rb\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .c, actual: .c\n",
      "predicted: .py, actual: .py\n"
     ]
    }
   ],
   "source": [
    "logits_tensor = tf.contrib.util.make_ndarray(response.outputs['logits'])\n",
    "predict_tensor = tf.contrib.util.make_ndarray(response.outputs['prediction'])\n",
    "\n",
    "language_codes_array = np.array(['UNKNOWN','.py','.c','.rb'])\n",
    "predicted_laguage_codes=language_codes_array[predict_tensor]\n",
    "print logits_tensor\n",
    "accuracy = np.mean(predicted_laguage_codes == language_codes)\n",
    "print \"accuracy: {}\".format(accuracy)\n",
    "for predicted_language_code, actual_language_code in zip(predicted_laguage_codes, language_codes):\n",
    "    print 'predicted: {}, actual: {}'.format(predicted_language_code, actual_language_code)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
